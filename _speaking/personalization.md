---
title: When Personalization Goes Wrong
summary: 
event: Confab 2019
event_url: https://www.confabevents.com/videos/2019-lightning-talks
video_url: https://vimeo.com/336425802
video_asset: https://player.vimeo.com/video/336425802?autoplay=1#t=338s
slides_url: 
slides_notes_url: 
---

So, content personalization. Who here is familiar with it, show of hands? Basically it’s the idea of taking information that you know about the people who are coming to your website or your digital presence, and using that stuff you know about them to give them what they want, or to convince them to do things that you want them to do.

Now, most conversations about personalization are basically executive fan fiction about making money, or sales pitches from people who have a million-dollar product they want you to use. This is going to be a slightly different talk. It is not a talk about solutions, but we’re going to give a little groundwork.

First, personalization starts with signals, those bits of information you know about someone. Stuff like they’re looking at the website at 2 o’clock, they told us their name is Bob, they’re logging in from Safari, stuff like that. It’s the basic facts you have. Scenarios are the stories that you tell yourself about what you think is going on based on that information. Like, “Oh, they’re logging in from a different location than they did last time, so I bet they’re traveling. We’ll say they’re a traveler.” Reactions are what you do differently based on those scenarios you think you’re in. For example, I think Bob is traveling, so we’re going to show him ads for luggage instead of couches. Pretty straightforward, pretty simple system.

Goals and metrics are the final part of that. They’re basically how you measure whether or not your reactions are actually accomplishing what you’re trying to get at. In theory, that probably should’ve been the first thing, but not everything goes perfectly. That’s what we’re going to talk about.

Personalization can go really, really bad, and it’s important to think about those scenarios. This is not a solution-based talk; this is a problem talk. Man, I love that photo. The first and most obvious one, again, is not having goals and metrics in place when you start out. If you don’t know how to measure whether you’re succeeding, you’re just going to drift randomly with the tool that somebody told you to install, and that’s no good.

The second one is not having structured content, not investing in taxonomy and the basic information any system you have will need to use to actually match up content with people. It’s basically just a blob in a mess, and it won’t work for you.

The third one is just-so assumptions. Basically, those stories you’ve told yourself about the scenarios that people are in may work in just the perfect example you thought of when you built out the system, but it falls apart in all of the real-world situations that users find themselves in.

The fourth one is unreliable signals. Basically, not realizing that those bits of data that you’re depending on to know what’s going on, aren’t reliable. Like it only works if they have the GPS on their phone turned on, or we assume that the same person is always using the same account.

The other one is editorial overload. Basically, you’ve created so many different variations of your content that the team you have to actually write and manage and update the stuff can’t actually keep up with all of the work, and it falls into disrepair. That’s no good.

The other one is creepy messaging. We’ve all seen that. It’s like inappropriate levels of intimacy, or something they didn’t actually tell you, you’re guessing at it, and getting those things right is even worse than getting them wrong, sometimes. Right.

It can actually go even worse. Things like bias amplification where those scenarios that you’ve imagined aren’t actually just figuring out what’s really going on. You’re telling yourself a story, but what you get from your systems is just reinforcing bad assumptions.

Illegal discrimination is possible, especially if you work in fields like job seeking, healthcare, housing. You can actually build systems without intending to that do illegal things and harm marginalized communities.

Oh, a pause there. Subversion by bad actors. It’s very easy, especially if your personalization tool builds things that the rest of the public will ultimately see, like most popular content. That can be leveraged by people who want to do harm, even if you don’t anticipate it.

The worst case scenario is very bad indeed. Recently a fairly simple algorithm changed by Facebook to the feed structure was used by the Myanmar government to conduct a propaganda campaign that resulted in thousands of deaths. It can be really bad.

Now, I said this wasn’t about solutions, but it is just a little bit. These are some really great books as you start working on building out a system that can help you think through what your assumptions are, what the impact can have on other people who will be touched by the personalization systems.

Some key things to take away are, know your goals, know the limits of your data and your assumptions, invest in structured content so the system can actually work, and have people whose job is to figure out how this could be broken, not just how it will work. Finally, prioritize a team that’s diverse and values the needs and the safety of a wide variety of people who will be touched by your systems. Put that before KPIs and metrics.

Thank you very much!

